{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10.10_1_prepare_data.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ddfo42JUxiv2"},"source":["\n","# TensorFlow Object Detection: Подготовка данных для обучения\n","\n","https://github.com/tensorflow/models/tree/master/research/object_detection"]},{"cell_type":"markdown","metadata":{"id":"BNXSkTUskE2G"},"source":["### Монтирование Google Drive\n","Для данного демо нам понадобятся несколько ноутбуков, которые должны работать с одними и теме же данными. Поэтому, чтобы все ноутбуки имели доступ к нужным данным, нам будет необходимо подключить диск Google Drive и сохранять все данные на нём (включая данные, скачанные из интернета).\n","\n","Для монтирования диска нужно выполнить данный блок, перейти по ссылке, получить код, скопировать его в поле ниже (в этом блоке) и нажать Enter\n","\n","После монтирования диск будет находиться здесь: `/content/drive/My Drive`"]},{"cell_type":"code","metadata":{"id":"HAsG6Dc8kuQk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629251233246,"user_tz":-180,"elapsed":21946,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"18c8a993-4f12-482a-c4a5-b95c993b1167"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xnnmVH__kx5B"},"source":["### Рабочая директория\n","Все данные будем хранить в директории `/content/drive/My Drive/tf_od_demo` (TensorFlow Object Detection Demo)\n","\n","При первом запуске создадим директорию (если её еще не существует), в противном случае надо заменить True на False.\n","\n","При последующих подключениях к диску (в том числе в других ноутбуках) директорию создавать не надо, в ней уже будут сохранены все данные, которые мы туда поместили."]},{"cell_type":"code","metadata":{"id":"khoZUcm6lrbu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629251233247,"user_tz":-180,"elapsed":17,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"282f847f-b4d3-46cf-9158-a38e2a250667"},"source":["if True:\n","    !mkdir \"/content/drive/My Drive/tf_od_demo\"\n","%cd \"/content/drive/My Drive/tf_od_demo\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/My Drive/tf_od_demo’: File exists\n","/content/drive/My Drive/tf_od_demo\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kk53xwHtalrN"},"source":["### Подготовка библиотеки `object_detection`\n","Библиотека `object_detection` находится в репозитории `tensorflow/models` в разделе `research`\n","\n","Необходимо склонировать код библиотеки и сконфигурировать модели (сбилдить прото модели).\n","\n","Этот шаг нужно сделать один раз (не повторять, если папка `models` уже находится в текущей директории).\n","\n","Подробнее: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fiik2Gc-G5F1","executionInfo":{"status":"ok","timestamp":1629251245905,"user_tz":-180,"elapsed":3293,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"d0baad5b-b7e9-4b85-c381-2c521ab4aa4d"},"source":["pip install tf_slim"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tf_slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 35.3 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 352 kB 7.7 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Dx_Hcsbkov3","executionInfo":{"status":"ok","timestamp":1629251248468,"user_tz":-180,"elapsed":2567,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"8459a3aa-0a83-448d-dc00-1ce5cd0d86ae"},"source":["pip install lvis"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.1)\n","Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.24)\n","Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.4.7)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.10.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.2)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n","Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n","Installing collected packages: lvis\n","Successfully installed lvis-0.5.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uOlZ5vLRHQ1t","executionInfo":{"status":"ok","timestamp":1629251695407,"user_tz":-180,"elapsed":446186,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"1bbd0a7b-f224-4a7f-e6d7-fbce94006c88"},"source":["pip install tf-models-official"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting tf-models-official\n","  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 8.4 MB/s \n","\u001b[?25hCollecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n","\u001b[K     |████████████████████████████████| 37.1 MB 47 kB/s \n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.4.0)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\n","\u001b[K     |████████████████████████████████| 679 kB 72.3 MB/s \n","\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (7.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (3.2.2)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.0.1)\n","Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.1.5)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.0.2)\n","Collecting tensorflow-text>=2.5.0\n","  Downloading tensorflow_text-2.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.3 MB)\n","\u001b[K     |████████████████████████████████| 4.3 MB 55.3 MB/s \n","\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.1.3)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.12.0)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.19.5)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.29.24)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.12.8)\n","Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.1.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 62.9 MB/s \n","\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.5.12)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.15.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 62.9 MB/s \n","\u001b[?25hCollecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 13.9 MB/s \n","\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n","\u001b[K     |████████████████████████████████| 211 kB 69.2 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.6.0)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (5.4.8)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 13.5 MB/s \n","\u001b[?25hRequirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.26.3)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.34.0)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.17.4)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.0.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (3.0.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2018.9)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.17.3)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (1.53.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (21.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (57.4.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.23.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.2.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.7.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2021.5.30)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (4.62.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (5.0.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.4.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.0.4)\n","Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (2.6.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (1.12.1)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (0.4.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (0.12.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (3.7.4.3)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (3.1.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (3.3.0)\n","Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (2.6.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (2.6.0)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (5.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (1.1.2)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (0.2.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (1.1.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (1.12)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (1.39.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (1.6.3)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (1.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (3.3.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (0.4.5)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (1.0.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (4.6.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (3.1.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.6)\n","Collecting tensorflow>=2.5.0\n","  Downloading tensorflow-2.5.1-cp37-cp37m-manylinux2010_x86_64.whl (454.4 MB)\n","\u001b[K     |████████████████████████████████| 454.4 MB 10 kB/s \n","\u001b[?25hCollecting keras-nightly~=2.5.0.dev\n","  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 43.0 MB/s \n","\u001b[?25hCollecting tensorflow>=2.5.0\n","  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n","\u001b[K     |████████████████████████████████| 454.3 MB 18 kB/s \n","\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of dm-tree to determine which version is compatible with other requirements. This could take a while.\n","Collecting dm-tree~=0.1.1\n","  Downloading dm_tree-0.1.6-cp37-cp37m-manylinux_2_24_x86_64.whl (93 kB)\n","\u001b[K     |████████████████████████████████| 93 kB 3.2 MB/s \n","\u001b[?25h  Downloading dm_tree-0.1.5-cp37-cp37m-manylinux1_x86_64.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 69.3 MB/s \n","\u001b[?25h  Downloading dm_tree-0.1.4-cp37-cp37m-manylinux1_x86_64.whl (293 kB)\n","\u001b[K     |████████████████████████████████| 293 kB 70.6 MB/s \n","\u001b[?25h  Downloading dm_tree-0.1.2-cp37-cp37m-manylinux1_x86_64.whl (290 kB)\n","\u001b[K     |████████████████████████████████| 290 kB 80.0 MB/s \n","\u001b[?25h  Downloading dm_tree-0.1.1-cp37-cp37m-manylinux1_x86_64.whl (289 kB)\n","\u001b[K     |████████████████████████████████| 289 kB 19.8 MB/s \n","\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-model-optimization to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172 kB)\n","\u001b[K     |████████████████████████████████| 172 kB 81.6 MB/s \n","\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of dm-tree to determine which version is compatible with other requirements. This could take a while.\n","  Downloading tensorflow_model_optimization-0.4.1-py2.py3-none-any.whl (172 kB)\n","\u001b[K     |████████████████████████████████| 172 kB 76.7 MB/s \n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n","INFO: pip is looking at multiple versions of tensorflow-hub to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow-hub>=0.6.0\n","  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n","\u001b[K     |████████████████████████████████| 108 kB 73.2 MB/s \n","\u001b[?25h  Downloading tensorflow_hub-0.11.0-py2.py3-none-any.whl (107 kB)\n","\u001b[K     |████████████████████████████████| 107 kB 78.7 MB/s \n","\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-model-optimization to determine which version is compatible with other requirements. This could take a while.\n","  Downloading tensorflow_hub-0.10.0-py2.py3-none-any.whl (107 kB)\n","\u001b[K     |████████████████████████████████| 107 kB 76.2 MB/s \n","\u001b[?25h  Downloading tensorflow_hub-0.9.0-py2.py3-none-any.whl (103 kB)\n","\u001b[K     |████████████████████████████████| 103 kB 74.8 MB/s \n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n","  Downloading tensorflow_hub-0.8.0-py2.py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 14.0 MB/s \n","\u001b[?25h  Downloading tensorflow_hub-0.7.0-py2.py3-none-any.whl (89 kB)\n","\u001b[K     |████████████████████████████████| 89 kB 10.4 MB/s \n","\u001b[?25h  Downloading tensorflow_hub-0.6.0-py2.py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 4.9 MB/s \n","\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-hub to determine which version is compatible with other requirements. This could take a while.\n","INFO: pip is looking at multiple versions of tensorflow-estimator to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow-estimator~=2.6\n","  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 41.7 MB/s \n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n","INFO: pip is looking at multiple versions of tensorboard-plugin-wit to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorboard-plugin-wit>=1.6.0\n","  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n","\u001b[K     |████████████████████████████████| 781 kB 57.1 MB/s \n","\u001b[?25h  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n","\u001b[K     |████████████████████████████████| 779 kB 60.5 MB/s \n","\u001b[?25h  Downloading tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl (777 kB)\n","\u001b[K     |████████████████████████████████| 777 kB 67.6 MB/s \n","\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-estimator to determine which version is compatible with other requirements. This could take a while.\n","  Downloading tensorboard_plugin_wit-1.6.0.post2-py3-none-any.whl (775 kB)\n","\u001b[K     |████████████████████████████████| 775 kB 74.4 MB/s \n","\u001b[?25hINFO: pip is looking at multiple versions of tensorboard-data-server to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 51.1 MB/s \n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n","INFO: pip is looking at multiple versions of tensorboard-plugin-wit to determine which version is compatible with other requirements. This could take a while.\n","  Downloading tensorboard_data_server-0.6.0-py3-none-manylinux2010_x86_64.whl (3.9 MB)\n","\u001b[K     |████████████████████████████████| 3.9 MB 59.0 MB/s \n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n","INFO: pip is looking at multiple versions of oauthlib to determine which version is compatible with other requirements. This could take a while.\n","Collecting oauthlib>=3.0.0\n","  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n","\u001b[K     |████████████████████████████████| 146 kB 77.0 MB/s \n","\u001b[?25h  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 70.2 MB/s \n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LPueN9mCBpHy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629178058289,"user_tz":-180,"elapsed":92122,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"44b5add5-774e-498f-a9de-e97274547963"},"source":["if True:\n","  \n","    !git clone https://github.com/tensorflow/models\n","    !cd models/research && protoc object_detection/protos/*.proto --python_out=.\n","    !cd models/research && export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim && python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'models'...\n","remote: Enumerating objects: 60242, done.\u001b[K\n","remote: Counting objects: 100% (8/8), done.\u001b[K\n","remote: Compressing objects: 100% (8/8), done.\u001b[K\n","remote: Total 60242 (delta 1), reused 7 (delta 0), pack-reused 60234\u001b[K\n","Receiving objects: 100% (60242/60242), 573.74 MiB | 13.85 MiB/s, done.\n","Resolving deltas: 100% (41927/41927), done.\n","Checking out files: 100% (2596/2596), done.\n","2021-08-17 05:27:31.880065: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RFCMljCEx9VW"},"source":["### Загрузка библиотек\n","Загрузка TensorFlow и других библиотек. Кроме того, загрузка модуля `dataset_util` из пакета `object_detection`, который будет нужен для создания датасета в нужном формате."]},{"cell_type":"code","metadata":{"id":"jH8kQ2q30B03","executionInfo":{"status":"ok","timestamp":1629251700033,"user_tz":-180,"elapsed":4632,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}}},"source":["import pandas as pd\n","import os\n","from PIL import Image\n","\n","import tensorflow as tf\n","\n","import sys\n","sys.path.insert(0, 'models/research')\n","\n","from object_detection.utils import dataset_util"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZmalcqDcwWG"},"source":["### Функция для создания одного обучающего образца\n","В этой функции создаётся экземпляр класса `tf.train.Example`, который соответствует одной обучающей картике. Ей могут соответствовать несколько ground-truth баундинг боксов. Однако, конкретно в данном примере на картинке есть строго один бокс. В противном случае списки `xmins`, `xmaxs`, `ymins`, `ymaxs`, `classes_text`, `classes` должны иметь соответствующее количество элементов ( = кол-ву боксов на данной картинке).\n","\n","Создавать экземпляры класса `tf.train.Example` можно произвольным способом. В данном примере на вход в функцию подаётся строка из CSV файла (`annot.csv`). Главное -- заполнить соовтестсвующие поля словаре `feature={...}`\n","\n","Подробнее: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md"]},{"cell_type":"code","metadata":{"id":"Dvz1hSw70OyQ","executionInfo":{"status":"ok","timestamp":1629251700036,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}}},"source":["def create_tf_example(example):\n","  \n","    img_fpath = os.path.join('my_data', example.id)\n","    img = Image.open(img_fpath)\n","    height = img.size[1]\n","    width = img.size[0]\n","    filename = str.encode(example.id)\n","    with open(img_fpath, mode='rb') as f:\n","        encoded_image_data = f.read()\n","    image_format = b'jpeg'\n","\n","    # List of normalized left x coordinates in bounding box (1 per box)\n","    xmins = [example.xmin1 / float(width), example.xmin2 / float(width), example.xmin3 / float(width),] \n","    # List of normalized right x coordinates in bounding box # (1 per box)\n","    xmaxs = [example.xmax1 / float(width), example.xmax2 / float(width), example.xmax3 / float(width)] \n","    # List of normalized top y coordinates in bounding box (1 per box)\n","    ymins = [example.ymin1 / float(height), example.ymin2 / float(height), example.ymin3 / float(height)] \n","    # List of normalized bottom y coordinates in bounding box # (1 per box)\n","    ymaxs = [example.ymax1 / float(height), example.ymax2 / float(height), example.ymax3 / float(height)] \n","    # List of string class name of bounding box (1 per box)\n","    classes_text = [b'Flash', b'Marker', b'Souvenir']\n","    # List of integer class id of bounding box (1 per box)\n","    classes = [1,2,3]\n","\n","    tf_example = tf.train.Example(features=tf.train.Features(feature={\n","        'image/height': dataset_util.int64_feature(height),\n","        'image/width': dataset_util.int64_feature(width),\n","        'image/filename': dataset_util.bytes_feature(filename),\n","        'image/source_id': dataset_util.bytes_feature(filename),\n","        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n","        'image/format': dataset_util.bytes_feature(image_format),\n","        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","        'image/object/class/label': dataset_util.int64_list_feature(classes),\n","    }))\n","    return tf_example"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ow1NNywGecQ2"},"source":["### Чтение CSV файла с разметкой\n","В данном файле представлена разметка обучающих изображений. Сам файл и его формат показаны лишь для примера, они никак не связаны с библиотекой `object_detection`. Наша финальная цель -- создать датасет в формате `TFRecord`, состоящий из экземпляров `tf.train.Example`.\n","\n","---\n","\n","В данном примере формат файла annot.csv следующий (один бокс на файл):\n","\n","id,xmin,ymin,xmax,ymax\n","\n","1.jpg,261,260,601,615\n","\n","2.jpg,130,429,401,734\n","\n","...\n","\n","---\n","\n","Перед запуском этого блока загрузите необходимые данные (папка `my_data`) в текущую рабочую директорию (tf_od_demo). Один из вариантов, как это можно сделать, это загрузить архив `my_data.7z`, а затем разархивировать его с помощью команды:\n","\n","`!7z x my_data.7z`"]},{"cell_type":"code","metadata":{"id":"k8alLq1uilZz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629178073654,"user_tz":-180,"elapsed":277,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"14818fd0-ca94-4283-d7a1-981f30f9c642"},"source":["if True:\n","    !7z x 10.7_my_data.7z"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n","p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n","\n","Scanning the drive for archives:\n","  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b\n","ERROR: No more files\n","10.7_my_data.7z\n","\n","\n","\n","System ERROR:\n","Unknown error -2147024872\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YpwJXq1SYy7S","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1629251700391,"user_tz":-180,"elapsed":361,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"d02ce28c-0ad1-4326-f3db-f269637c0c88"},"source":["annot = pd.read_csv('./my_data/annot.csv', sep=';')\n","annot.head()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>xmin1</th>\n","      <th>ymin1</th>\n","      <th>xmax1</th>\n","      <th>ymax1</th>\n","      <th>xmin2</th>\n","      <th>ymin2</th>\n","      <th>xmax2</th>\n","      <th>ymax2</th>\n","      <th>xmin3</th>\n","      <th>ymin3</th>\n","      <th>xmax3</th>\n","      <th>ymax3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.jpg</td>\n","      <td>390</td>\n","      <td>580</td>\n","      <td>560</td>\n","      <td>720</td>\n","      <td>740</td>\n","      <td>350</td>\n","      <td>925</td>\n","      <td>470</td>\n","      <td>950</td>\n","      <td>255</td>\n","      <td>1070</td>\n","      <td>350</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.jpg</td>\n","      <td>180</td>\n","      <td>450</td>\n","      <td>390</td>\n","      <td>500</td>\n","      <td>650</td>\n","      <td>370</td>\n","      <td>710</td>\n","      <td>670</td>\n","      <td>920</td>\n","      <td>450</td>\n","      <td>1040</td>\n","      <td>520</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.jpg</td>\n","      <td>190</td>\n","      <td>710</td>\n","      <td>440</td>\n","      <td>770</td>\n","      <td>830</td>\n","      <td>230</td>\n","      <td>930</td>\n","      <td>320</td>\n","      <td>890</td>\n","      <td>370</td>\n","      <td>1080</td>\n","      <td>430</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.jpg</td>\n","      <td>1000</td>\n","      <td>330</td>\n","      <td>1100</td>\n","      <td>430</td>\n","      <td>790</td>\n","      <td>200</td>\n","      <td>960</td>\n","      <td>330</td>\n","      <td>220</td>\n","      <td>650</td>\n","      <td>480</td>\n","      <td>840</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.jpg</td>\n","      <td>260</td>\n","      <td>660</td>\n","      <td>500</td>\n","      <td>720</td>\n","      <td>900</td>\n","      <td>310</td>\n","      <td>1020</td>\n","      <td>430</td>\n","      <td>440</td>\n","      <td>250</td>\n","      <td>580</td>\n","      <td>340</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  xmin1  ymin1  xmax1  ymax1  ...  ymax2  xmin3  ymin3  xmax3  ymax3\n","0  1.jpg    390    580    560    720  ...    470    950    255   1070    350\n","1  2.jpg    180    450    390    500  ...    670    920    450   1040    520\n","2  3.jpg    190    710    440    770  ...    320    890    370   1080    430\n","3  4.jpg   1000    330   1100    430  ...    330    220    650    480    840\n","4  5.jpg    260    660    500    720  ...    430    440    250    580    340\n","\n","[5 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"90HTWYRmhRrP"},"source":["### Создание TFRecord\n","Здесь мы создаём финальный датасет в формате `TFRecord`, который необходим для запуска обучения TF Object Detection. \n","\n","В цикле по всем обучающим образцам создаем `TF Example` и записываем его в `TF Record`."]},{"cell_type":"code","metadata":{"id":"ReFXnPuwZLoB","executionInfo":{"status":"ok","timestamp":1629251706821,"user_tz":-180,"elapsed":6434,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}}},"source":["writer = tf.io.TFRecordWriter('my_data/train_data.record')\n","\n","for idx, row in annot.iterrows():\n","    tf_example = create_tf_example(row)\n","    writer.write(tf_example.SerializeToString())\n","\n","writer.close()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Bl1CWfDr7QF"},"source":[""],"execution_count":null,"outputs":[]}]}