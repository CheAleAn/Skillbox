{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для занятия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>word</th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>в</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>и</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>который</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0</td>\n",
       "      <td>шерлок</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>с</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>сериал</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>риколетти</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>история</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>для</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>о</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_id       word  dummy\n",
       "6         0          в     10\n",
       "29        0          и      7\n",
       "37        0    который      5\n",
       "111       0     шерлок      4\n",
       "77        0          с      4\n",
       "84        0     сериал      4\n",
       "75        0  риколетти      3\n",
       "31        0    история      2\n",
       "21        0        для      2\n",
       "49        0          о      2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "\n",
    "\n",
    "text_df = pd.read_csv(\"./data/content_description.csv\", sep='\\t')\n",
    "text_df.head()\n",
    "\n",
    "# разбиваем тест на слова\n",
    "corpus = []\n",
    "# регулярка для поиска слов\n",
    "regular_expr = r'\\w+'\n",
    "reg_expr_compiled = re.compile(regular_expr)\n",
    "# формируем датасет из отдельных слов\n",
    "for raw_text in text_df.description.values:\n",
    "    # приводим к нижнему регистру\n",
    "    raw_text_lower = raw_text.lower()\n",
    "    # разбиваем текст на слова\n",
    "    text_by_words = reg_expr_compiled.findall(raw_text_lower) \n",
    "    corpus.append(text_by_words)\n",
    "\n",
    "# нормализация текста\n",
    "normalized_corpus = []\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "# нормализуем каждое слово в тексте\n",
    "for token_list in corpus:\n",
    "    normalized_token_list = []\n",
    "    for word in token_list:\n",
    "        parsed_token = morph.parse(word)\n",
    "        normal_form = parsed_token[0].normal_form\n",
    "        normalized_token_list.append(normal_form)\n",
    "    normalized_corpus.append(normalized_token_list)\n",
    "\n",
    "# превращаем в DataFrame\n",
    "doc_count = len(normalized_corpus)\n",
    "doc_ids = []\n",
    "tokens = []\n",
    "# формируем два списка-колонки датафрейма\n",
    "for doc_id in range(doc_count):\n",
    "    for token in normalized_corpus[doc_id]:\n",
    "        doc_ids.append(doc_id)\n",
    "        tokens.append(token)\n",
    "\n",
    "tokens_df = pd.DataFrame({\n",
    "    'doc_id': doc_ids,\n",
    "    'word': tokens\n",
    "})\n",
    "# дамми-столбец\n",
    "tokens_df = tokens_df.assign(dummy = 1)\n",
    "# аггрегируем статистики\n",
    "word_count_df = tokens_df.groupby(['doc_id','word'])['dummy'].count().reset_index()\n",
    "\n",
    "word_count_df[word_count_df.doc_id==0].sort_values(by='dummy', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ivi.ru/watch/157318/description</td>\n",
       "      <td>Лучший подарок, который только можно было прид...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ivi.ru/watch/98336/description</td>\n",
       "      <td>Через какие трудности приходится проходить Сан...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ivi.ru/watch/183533/description</td>\n",
       "      <td>Миловидный Давид - позор для своего отца. Не в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ivi.ru/watch/157319/description</td>\n",
       "      <td>Экранизация сатирического бестселлера Стивена ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ivi.ru/watch/51342/description</td>\n",
       "      <td>«Леди удача» – авантюрная романтическая комеди...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.ivi.ru/watch/183534/description</td>\n",
       "      <td>На поминках Сюзанна узнает, что Джефф изменял ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.ivi.ru/watch/112509/description</td>\n",
       "      <td>Культовый японский фильм ужасов, заставляющий ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.ivi.ru/watch/157320/description</td>\n",
       "      <td>Двое выпускников калифорнийской школы бизнеса ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       content  \\\n",
       "0  https://www.ivi.ru/watch/157318/description   \n",
       "1   https://www.ivi.ru/watch/98336/description   \n",
       "2  https://www.ivi.ru/watch/183533/description   \n",
       "3  https://www.ivi.ru/watch/157319/description   \n",
       "4   https://www.ivi.ru/watch/51342/description   \n",
       "5  https://www.ivi.ru/watch/183534/description   \n",
       "6  https://www.ivi.ru/watch/112509/description   \n",
       "7  https://www.ivi.ru/watch/157320/description   \n",
       "\n",
       "                                         description  \n",
       "0  Лучший подарок, который только можно было прид...  \n",
       "1  Через какие трудности приходится проходить Сан...  \n",
       "2  Миловидный Давид - позор для своего отца. Не в...  \n",
       "3  Экранизация сатирического бестселлера Стивена ...  \n",
       "4  «Леди удача» – авантюрная романтическая комеди...  \n",
       "5  На поминках Сюзанна узнает, что Джефф изменял ...  \n",
       "6  Культовый японский фильм ужасов, заставляющий ...  \n",
       "7  Двое выпускников калифорнийской школы бизнеса ...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.3  Домашняя работа\n",
    "\n",
    "10.3.1 **Задание простого уровня** Для каждого слова подсчитайте процент документов, в которых содержится это слово. Сформируйте dataframe doc_frequency. Процен документов вычисляется по формуле\n",
    "$$\n",
    "d = \\frac{m}{n} \\times 100\n",
    "$$\n",
    "где $m$ - количество документов, в которых встретилось это слово, а $n$ - общее количество документов. Значение в процентах округлите до целых.\n",
    "\n",
    "Посмотрите какие слова оказались в топе - это предлоги и частицы. Такие слова присутствуют во всех документах, а значит, их можно удалить из текста, чтобы оставшиеся слова были более \"осмысленными\". Это упростит анализ текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>свой</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>онлайн</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>год</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>смотреть</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>всё</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>самый</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>который</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>дело</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>жертва</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>история</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word   freq\n",
       "53       свой  0.750\n",
       "113    онлайн  0.750\n",
       "67        год  0.625\n",
       "112  смотреть  0.625\n",
       "17        всё  0.500\n",
       "41      самый  0.500\n",
       "2     который  0.500\n",
       "86       дело  0.375\n",
       "421    жертва  0.375\n",
       "71    история  0.375"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- ВАШ КОД ЗДЕСЬ --\n",
    "all_docs = text_df.shape[0]\n",
    "lst = [[this_word, len(pd.unique(tokens_df.groupby(['word']).get_group(this_word)['doc_id']).tolist())/all_docs] for this_word in pd.unique(tokens_df['word']).tolist()]\n",
    "doc_frequency = pd.DataFrame(lst, columns=['word', 'freq']).sort_values('freq', ascending=False).drop(index=[19,15,45,77,107,103,169,72,60,110,199,79,37,173,253,331,191,146,145,92])\n",
    "\n",
    "doc_frequency.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.3.2 **Задание среднего уровня**\n",
    "\n",
    "Воспользуйтесь регулярными выражениями, чтобы извлечь из текста все пары **имя+фамилия**.\n",
    "\n",
    "* неформальное описание регулярки: пара слов идущая друг за другом, каждое из которых начинается с заглавной буквы\n",
    "* анализировать нужно только `doc_id=3`\n",
    "* текст берём из исходного датафрейма `text_df`\n",
    "* заглавная буква в русскоязычном тексте соответствует символьному классу `r'[A-Я]*'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Экранизация сатирического бестселлера Стивена Фрая, мастерски воплощенная британским режиссером и продюсером Джоном Дженксом.   У Теда Уоллеса было славное прошлое, и вот-вот его книги должны были пополнить стройный ряд томов британских классиков. Но его жуткий характер вкупе с алкоголизмом и мизантропией в запущенной стадии испортили все. Теперь Тед зарабатывает на жизнь тем, что поносит в своих статьях спектакли, которые вообще-то не стоят его внимания. И продолжает пить. Вскоре Тед лишается и этого: его бесконечное ворчание достало всю редакцию.  Готовясь к голодной и бесславной смерти, внезапно Уоллес получает выгодное предложение от своей крестницы Джейн. Девушка недавно излечилась от болезни благодаря чуду и теперь предлагает Теду погостить в аристократическом доме, чтобы осветить происходящие здесь чудеса исцеления.  Старый скептик соглашается из корыстных побуждений и даже представить не может, сколько сюрпризов ему уготовано.  Смотреть онлайн эту комедию о том, что даже самые заядлые скептики тайно готовы верить в невозможное, можно на нашем сайте.\n",
      "Стивена Фрая\n",
      "Джоном Дженксом\n",
      "Теда Уоллеса\n"
     ]
    }
   ],
   "source": [
    "# -- ВАШ КОД ЗДЕСЬ --\n",
    "raw_text = text_df.description.values[3]\n",
    "# регулярка - её нужно поправить\n",
    "reg_expr = r'\\w\\s([A-Я]{1}\\w*\\s[A-Я]{1}\\w*)'\n",
    "# компилируем регулярное выражение\n",
    "reg_expr_compiled = re.compile(reg_expr)\n",
    "# применяем выражение к тексту\n",
    "print(raw_text)\n",
    "for g in reg_expr_compiled.findall(raw_text):\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.3.3 **Задание сложного уровня**. Словарь `genre_dict` содержит слова, которые являются характерными для того или иного жанра. Пользуясь словарём, а так же таблицей `word_count_df`, сформируйте таблицу двумя колонками `doc_id | genre` с жанрами фильмов.\n",
    "\n",
    "Для этого нужно\n",
    "* превратить словарь `genre_dict` в DataFrame формата `word | genre`\n",
    "* соединить полученный датафрейм с помощью функции `merge` c ранее полученным датафреймом `word_count_df`, котороый содержит распределение слов по документам. Воспользуйтесь методом соединения `inner`\n",
    "* для каждого документа выбрать жанр документа - это совокупность жанров слов отдельных слов. У одного контента может быть несколько жанров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>детектив</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>триллер</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>сказка</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>мелодрама</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>комедия</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>комедия</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>триллер</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id      genre  dummy\n",
       "0       0   детектив      3\n",
       "1       0    триллер      1\n",
       "2       1     сказка      1\n",
       "3       2  мелодрама      2\n",
       "4       3    комедия      1\n",
       "5       4    комедия      2\n",
       "6       6    триллер      3"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "genre_dict = {\n",
    "    'комедия': ['сатирический', 'авантюрный', 'забавный'],\n",
    "    'мелодрама': ['выбор', 'позор'],\n",
    "    'сказка': ['приключения', 'милый', 'семейный'],\n",
    "    'детектив': ['тайна', 'разгадать', 'загадочный'], \n",
    "    'триллер': ['ужас', 'зловещий', 'нерв']\n",
    "}\n",
    "\n",
    "nested_genres =[[(i, j) for j in genre_dict[i]] for i in genre_dict]\n",
    "# переводим из словаря к более удобному виду\n",
    "flatten_genres = list(itertools.chain(*nested_genres))\n",
    "# создаём DataFrame\n",
    "genres_df = pd.DataFrame(flatten_genres, columns = ['genre', 'character_word'])\n",
    "\n",
    "doc_to_genres = word_count_df\\\n",
    "                .merge(genres_df, left_on='word', right_on='character_word')\\\n",
    "                .groupby(['doc_id','genre'])['dummy'].count().reset_index()\n",
    "doc_to_genres.sort_values(by=['doc_id'], ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
