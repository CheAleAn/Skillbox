{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"10.10_2_train.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"markdown","metadata":{"id":"gfTa7OPRE90x"},"source":["\n","# TensorFlow Object Detection: Обучение модели\n","\n","https://github.com/tensorflow/models/tree/master/research/object_detection"]},{"cell_type":"markdown","metadata":{"id":"Zs5lmvlhnjQ3"},"source":["### Монтирование Google Drive\n","Для данного демо нам понадобятся несколько ноутбуков, которые должны работать с одними и теме же данными. Поэтому, чтобы все ноутбуки имели доступ к нужным данным, нам будет необходимо подключить диск Google Drive и сохранять все данные на нём (включая данные, скачанные из интернета).\n","\n","Для монтирования диска нужно выполнить данный блок, перейти по ссылке, получить код, скопировать его в поле ниже (в этом блоке) и нажать Enter\n","\n","После монтирования диск будет находиться здесь: `/content/drive/My Drive`"]},{"cell_type":"code","metadata":{"id":"98xsCYnJnkZH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629075071370,"user_tz":-180,"elapsed":18366,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"1f9520c7-8197-48f2-fee6-d80d2dbd9a9f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oKUjRWkZnk5J"},"source":["### Рабочая директория\n","Все данные будем хранить в директории `/content/drive/My Drive/tf_od_demo` (TensorFlow Object Detection Demo)\n","\n","Директория должна быть уже создана (в предыдущем ноутбуке)"]},{"cell_type":"code","metadata":{"id":"ENuwHtlWnlHq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629075071371,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"35ebcdab-af78-4495-d978-b692ed944b8a"},"source":["%cd \"/content/drive/My Drive/tf_od_demo\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/tf_od_demo\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Dnn76S3HkXAQ"},"source":["### Загрузка предобученной модели\n","Во время обучения мы будем делать fine-tuning предобученной модели. Для этого необходимо загрузить веса соответствующей модели `ssd_mobilenet_v1_coco`. Из названия следует, что детекционная архитектура -- `SSD`, базовая CNN модель -- `MobileNet_v1`, предобучена на датасете COCO.\n","\n","Этот шаг нужно сделать один раз (не повторять, если модель уже была скачана ранее)."]},{"cell_type":"code","metadata":{"id":"bhwSdaEXE9NV","cellView":"both","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626177539059,"user_tz":-180,"elapsed":5130,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"af2e74a1-3d01-475e-9102-260c644470bf"},"source":["if True:\n","    !wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz\n","    !tar -xzf ssd_mobilenet_v1_coco_2018_01_28.tar.gz"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-07-13 11:58:55--  http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.133.128, 2a00:1450:400c:c07::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.133.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 76541073 (73M) [application/x-tar]\n","Saving to: ‘ssd_mobilenet_v1_coco_2018_01_28.tar.gz’\n","\n","ssd_mobilenet_v1_co 100%[===================>]  73.00M  41.0MB/s    in 1.8s    \n","\n","2021-07-13 11:58:57 (41.0 MB/s) - ‘ssd_mobilenet_v1_coco_2018_01_28.tar.gz’ saved [76541073/76541073]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_YH8fHVOpGpl"},"source":["### Подготовка данных для обучения\n","Ранее мы подготовили файл `train_data.record`, в котором содержится обучающий датасет.\n","Кроме него для обучения необходимо подготовить еще два файла (они также находятся в папке `my_data`)\n","\n","* `label_map.pbtxt` (в нашем случае `cube_label_map.pbtxt`) - файл с описанием классов. В нашем случае у нас всего один класс.\n","\n","* `pipeline.config` - файл, содержищий различне гиперпарамтеры и настройки обучения. Важные параметры: `num_classes`, `fine_tune_checkpoint`, `label_map_path`, `input_path`. В данном примере и для обучения и для теста используется один и тот же датасет (см. блоки параметров `train_input_reader`, `eval_input_reader`)"]},{"cell_type":"markdown","metadata":{"id":"WcbVj0II5PYc"},"source":["### Запуск обучения\n","После того, как мы подготовили все данные, запустить обучение очень просто: надо просто запустить скрипт `model_main.py` и передать ему соответствующие параметры.\n","\n","*   Путь к файлу `pipeline.config`\n","*   Директорию, для записи выхода обучения (`model_dir`)\n","*   Количество итераций обучения (`num_train_steps`)\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":129},"id":"yssjJpYQNazr","executionInfo":{"status":"error","timestamp":1629075075813,"user_tz":-180,"elapsed":217,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"b8144518-ed13-4f44-e01c-286bd388787d"},"source":["pip install tf_slim\n","pip install lvis\n","pip install tf-models-official\n","pip install tensorflow==1.15.5"],"execution_count":3,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-1801e9d86ec7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install tf_slim\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"frcRPRXEjUtP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629079941529,"user_tz":-180,"elapsed":4539019,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"6e76345f-d8ba-4ab7-b041-f6d18ba65b10"},"source":["%%time\n","\n","if False:\n","    # Delete output directory\n","    !rm -rf my_data/output\n","\n","!export PYTHONPATH=$PYTHONPATH:models/research:models/research/slim ; python models/research/object_detection/model_main.py \\\n","    --pipeline_config_path=my_data/pipeline.config \\\n","    --model_dir=my_data/output \\\n","    --num_train_steps=10000 \\\n","    --alsologtostderr"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0816 00:56:48.865751 139955924342656 model_lib.py:817] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting train_steps: 10000\n","I0816 00:56:48.865962 139955924342656 config_util.py:552] Maybe overwriting train_steps: 10000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0816 00:56:48.866077 139955924342656 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0816 00:56:48.866162 139955924342656 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0816 00:56:48.866246 139955924342656 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0816 00:56:48.866374 139955924342656 model_lib.py:833] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n","I0816 00:56:48.866468 139955924342656 model_lib.py:870] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n","INFO:tensorflow:Using config: {'_model_dir': 'my_data/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f49c225d590>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","I0816 00:56:48.867004 139955924342656 estimator.py:212] Using config: {'_model_dir': 'my_data/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f49c225d590>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f49c225e050>) includes params argument, but params are not passed to Estimator.\n","W0816 00:56:48.867211 139955924342656 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f49c225e050>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I0816 00:56:48.867606 139955924342656 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I0816 00:56:48.867773 139955924342656 training.py:612] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","I0816 00:56:48.867973 139955924342656 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0816 00:56:48.879186 139955924342656 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 00:56:49.171609 139955924342656 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 00:56:49.173257 139955924342656 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0816 00:56:49.173422 139955924342656 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0816 00:56:49.173508 139955924342656 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/drive/My Drive/tf_od_demo/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0816 00:56:49.178076 139955924342656 deprecation.py:323] From /content/drive/My Drive/tf_od_demo/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /content/drive/My Drive/tf_od_demo/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0816 00:56:49.195988 139955924342656 deprecation.py:323] From /content/drive/My Drive/tf_od_demo/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /content/drive/My Drive/tf_od_demo/models/research/object_detection/inputs.py:110: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0816 00:57:02.188499 139955924342656 deprecation.py:323] From /content/drive/My Drive/tf_od_demo/models/research/object_detection/inputs.py:110: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/My Drive/tf_od_demo/models/research/object_detection/inputs.py:94: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0816 00:57:02.345771 139955924342656 deprecation.py:323] From /content/drive/My Drive/tf_od_demo/models/research/object_detection/inputs.py:94: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0816 00:57:10.226023 139955924342656 api.py:332] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /content/drive/My Drive/tf_od_demo/models/research/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0816 00:57:15.166860 139955924342656 deprecation.py:323] From /content/drive/My Drive/tf_od_demo/models/research/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Calling model_fn.\n","I0816 00:57:19.271744 139955924342656 estimator.py:1148] Calling model_fn.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0816 00:57:19.332765 139955924342656 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 00:57:20.818611 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 00:57:20.846071 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 00:57:20.872215 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 00:57:20.898815 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 00:57:20.925222 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 00:57:20.951595 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0816 00:57:22.769765 139955924342656 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","INFO:tensorflow:Done calling model_fn.\n","I0816 00:57:26.260411 139955924342656 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I0816 00:57:26.261606 139955924342656 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I0816 00:57:28.089202 139955924342656 monitored_session.py:240] Graph was finalized.\n","2021-08-16 00:57:28.089580: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2021-08-16 00:57:28.092707: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000175000 Hz\n","2021-08-16 00:57:28.092891: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563d53527d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-08-16 00:57:28.092920: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","INFO:tensorflow:Restoring parameters from my_data/output/model.ckpt-7256\n","I0816 00:57:28.096137 139955924342656 saver.py:1284] Restoring parameters from my_data/output/model.ckpt-7256\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","W0816 00:57:30.828545 139955924342656 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","INFO:tensorflow:Running local_init_op.\n","I0816 00:57:31.283150 139955924342656 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0816 00:57:31.456001 139955924342656 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 7256 into my_data/output/model.ckpt.\n","I0816 00:57:36.483363 139955924342656 basic_session_run_hooks.py:606] Saving checkpoints for 7256 into my_data/output/model.ckpt.\n","INFO:tensorflow:loss = 0.87420017, step = 7257\n","I0816 00:57:46.825120 139955924342656 basic_session_run_hooks.py:262] loss = 0.87420017, step = 7257\n","INFO:tensorflow:global_step/sec: 0.613564\n","I0816 01:00:29.806883 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.613564\n","INFO:tensorflow:loss = 1.1737813, step = 7357 (162.983 sec)\n","I0816 01:00:29.808434 139955924342656 basic_session_run_hooks.py:260] loss = 1.1737813, step = 7357 (162.983 sec)\n","INFO:tensorflow:global_step/sec: 0.62271\n","I0816 01:03:10.395281 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.62271\n","INFO:tensorflow:loss = 1.5905186, step = 7457 (160.588 sec)\n","I0816 01:03:10.396876 139955924342656 basic_session_run_hooks.py:260] loss = 1.5905186, step = 7457 (160.588 sec)\n","INFO:tensorflow:global_step/sec: 0.62661\n","I0816 01:05:49.984270 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.62661\n","INFO:tensorflow:loss = 2.969738, step = 7557 (159.589 sec)\n","I0816 01:05:49.985753 139955924342656 basic_session_run_hooks.py:260] loss = 2.969738, step = 7557 (159.589 sec)\n","INFO:tensorflow:Saving checkpoints for 7626 into my_data/output/model.ckpt.\n","I0816 01:07:39.196363 139955924342656 basic_session_run_hooks.py:606] Saving checkpoints for 7626 into my_data/output/model.ckpt.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","W0816 01:07:39.442706 139955924342656 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 01:07:40.245125 139955924342656 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 01:07:40.246638 139955924342656 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0816 01:07:40.246801 139955924342656 dataset_builder.py:81] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0816 01:07:41.253724 139955924342656 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:07:42.671442 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:07:42.699740 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:07:42.731223 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:07:42.760025 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:07:42.787712 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:07:42.815896 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/drive/My Drive/tf_od_demo/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0816 01:07:43.467352 139955924342656 deprecation.py:323] From /content/drive/My Drive/tf_od_demo/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/drive/My Drive/tf_od_demo/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0816 01:07:43.658064 139955924342656 deprecation.py:323] From /content/drive/My Drive/tf_od_demo/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Done calling model_fn.\n","I0816 01:07:44.070764 139955924342656 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-08-16T01:07:44Z\n","I0816 01:07:44.085421 139955924342656 evaluation.py:255] Starting evaluation at 2021-08-16T01:07:44Z\n","INFO:tensorflow:Graph was finalized.\n","I0816 01:07:44.344871 139955924342656 monitored_session.py:240] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from my_data/output/model.ckpt-7626\n","I0816 01:07:44.347299 139955924342656 saver.py:1284] Restoring parameters from my_data/output/model.ckpt-7626\n","INFO:tensorflow:Running local_init_op.\n","I0816 01:07:44.892784 139955924342656 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0816 01:07:44.985692 139955924342656 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 8 images.\n","I0816 01:07:47.753694 139954629330688 coco_evaluation.py:293] Performing evaluation on 8 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0816 01:07:47.754128 139954629330688 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0816 01:07:47.754318 139954629330688 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.01s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","INFO:tensorflow:Finished evaluation at 2021-08-16-01:07:49\n","I0816 01:07:49.057153 139955924342656 evaluation.py:275] Finished evaluation at 2021-08-16-01:07:49\n","INFO:tensorflow:Saving dict for global step 7626: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 19.166267, Loss/localization_loss = 3.4915428, Loss/regularization_loss = 0.124459304, Loss/total_loss = 22.78227, global_step = 7626, learning_rate = 0.004, loss = 22.78227\n","I0816 01:07:49.057443 139955924342656 estimator.py:2049] Saving dict for global step 7626: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 19.166267, Loss/localization_loss = 3.4915428, Loss/regularization_loss = 0.124459304, Loss/total_loss = 22.78227, global_step = 7626, learning_rate = 0.004, loss = 22.78227\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7626: my_data/output/model.ckpt-7626\n","I0816 01:07:49.858607 139955924342656 estimator.py:2109] Saving 'checkpoint_path' summary for global step 7626: my_data/output/model.ckpt-7626\n","INFO:tensorflow:global_step/sec: 0.596764\n","I0816 01:08:37.554827 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.596764\n","INFO:tensorflow:loss = 1.1320817, step = 7657 (167.571 sec)\n","I0816 01:08:37.556446 139955924342656 basic_session_run_hooks.py:260] loss = 1.1320817, step = 7657 (167.571 sec)\n","INFO:tensorflow:global_step/sec: 0.628645\n","I0816 01:11:16.627004 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.628645\n","INFO:tensorflow:loss = 1.4232838, step = 7757 (159.072 sec)\n","I0816 01:11:16.628673 139955924342656 basic_session_run_hooks.py:260] loss = 1.4232838, step = 7757 (159.072 sec)\n","INFO:tensorflow:global_step/sec: 0.629651\n","I0816 01:13:55.445230 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.629651\n","INFO:tensorflow:loss = 1.463882, step = 7857 (158.818 sec)\n","I0816 01:13:55.446894 139955924342656 basic_session_run_hooks.py:260] loss = 1.463882, step = 7857 (158.818 sec)\n","INFO:tensorflow:global_step/sec: 0.626439\n","I0816 01:16:35.077794 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.626439\n","INFO:tensorflow:loss = 2.1529832, step = 7957 (159.633 sec)\n","I0816 01:16:35.079507 139955924342656 basic_session_run_hooks.py:260] loss = 2.1529832, step = 7957 (159.633 sec)\n","INFO:tensorflow:Saving checkpoints for 7998 into my_data/output/model.ckpt.\n","I0816 01:17:39.675494 139955924342656 basic_session_run_hooks.py:606] Saving checkpoints for 7998 into my_data/output/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 01:17:40.686643 139955924342656 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 01:17:40.688111 139955924342656 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0816 01:17:40.688267 139955924342656 dataset_builder.py:81] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0816 01:17:41.440390 139955924342656 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:17:42.854480 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:17:42.883692 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:17:42.912111 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:17:42.940284 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:17:42.971132 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:17:42.998772 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0816 01:17:44.229137 139955924342656 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-08-16T01:17:44Z\n","I0816 01:17:44.245637 139955924342656 evaluation.py:255] Starting evaluation at 2021-08-16T01:17:44Z\n","INFO:tensorflow:Graph was finalized.\n","I0816 01:17:44.518714 139955924342656 monitored_session.py:240] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from my_data/output/model.ckpt-7998\n","I0816 01:17:44.521136 139955924342656 saver.py:1284] Restoring parameters from my_data/output/model.ckpt-7998\n","INFO:tensorflow:Running local_init_op.\n","I0816 01:17:45.031710 139955924342656 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0816 01:17:45.120193 139955924342656 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 8 images.\n","I0816 01:17:47.861222 139954637723392 coco_evaluation.py:293] Performing evaluation on 8 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0816 01:17:47.866655 139954637723392 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0816 01:17:47.866874 139954637723392 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.00s).\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","INFO:tensorflow:Finished evaluation at 2021-08-16-01:17:49\n","I0816 01:17:49.106618 139955924342656 evaluation.py:275] Finished evaluation at 2021-08-16-01:17:49\n","INFO:tensorflow:Saving dict for global step 7998: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 19.744919, Loss/localization_loss = 3.6493082, Loss/regularization_loss = 0.12530287, Loss/total_loss = 23.519531, global_step = 7998, learning_rate = 0.004, loss = 23.519531\n","I0816 01:17:49.106872 139955924342656 estimator.py:2049] Saving dict for global step 7998: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 19.744919, Loss/localization_loss = 3.6493082, Loss/regularization_loss = 0.12530287, Loss/total_loss = 23.519531, global_step = 7998, learning_rate = 0.004, loss = 23.519531\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7998: my_data/output/model.ckpt-7998\n","I0816 01:17:49.114276 139955924342656 estimator.py:2109] Saving 'checkpoint_path' summary for global step 7998: my_data/output/model.ckpt-7998\n","INFO:tensorflow:global_step/sec: 0.601048\n","I0816 01:19:21.453835 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.601048\n","INFO:tensorflow:loss = 2.5675209, step = 8057 (166.376 sec)\n","I0816 01:19:21.455320 139955924342656 basic_session_run_hooks.py:260] loss = 2.5675209, step = 8057 (166.376 sec)\n","INFO:tensorflow:global_step/sec: 0.621097\n","I0816 01:22:02.459339 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.621097\n","INFO:tensorflow:loss = 2.3924167, step = 8157 (161.006 sec)\n","I0816 01:22:02.460929 139955924342656 basic_session_run_hooks.py:260] loss = 2.3924167, step = 8157 (161.006 sec)\n","INFO:tensorflow:global_step/sec: 0.622222\n","I0816 01:24:43.173602 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.622222\n","INFO:tensorflow:loss = 1.093536, step = 8257 (160.714 sec)\n","I0816 01:24:43.175340 139955924342656 basic_session_run_hooks.py:260] loss = 1.093536, step = 8257 (160.714 sec)\n","INFO:tensorflow:global_step/sec: 0.610009\n","I0816 01:27:27.105609 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.610009\n","INFO:tensorflow:loss = 2.0622492, step = 8357 (163.932 sec)\n","I0816 01:27:27.107205 139955924342656 basic_session_run_hooks.py:260] loss = 2.0622492, step = 8357 (163.932 sec)\n","INFO:tensorflow:Saving checkpoints for 8365 into my_data/output/model.ckpt.\n","I0816 01:27:40.816497 139955924342656 basic_session_run_hooks.py:606] Saving checkpoints for 8365 into my_data/output/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 01:27:41.831828 139955924342656 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 01:27:41.833738 139955924342656 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0816 01:27:41.833898 139955924342656 dataset_builder.py:81] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0816 01:27:42.608185 139955924342656 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:27:43.959882 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:27:43.989015 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:27:44.019680 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:27:44.049602 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:27:44.078794 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:27:44.108029 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0816 01:27:45.597657 139955924342656 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-08-16T01:27:45Z\n","I0816 01:27:45.612210 139955924342656 evaluation.py:255] Starting evaluation at 2021-08-16T01:27:45Z\n","INFO:tensorflow:Graph was finalized.\n","I0816 01:27:45.860156 139955924342656 monitored_session.py:240] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from my_data/output/model.ckpt-8365\n","I0816 01:27:45.862600 139955924342656 saver.py:1284] Restoring parameters from my_data/output/model.ckpt-8365\n","INFO:tensorflow:Running local_init_op.\n","I0816 01:27:46.402771 139955924342656 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0816 01:27:46.498821 139955924342656 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 8 images.\n","I0816 01:27:49.299073 139954637723392 coco_evaluation.py:293] Performing evaluation on 8 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0816 01:27:49.299573 139954637723392 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0816 01:27:49.299868 139954637723392 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.00s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","INFO:tensorflow:Finished evaluation at 2021-08-16-01:27:50\n","I0816 01:27:50.430066 139955924342656 evaluation.py:275] Finished evaluation at 2021-08-16-01:27:50\n","INFO:tensorflow:Saving dict for global step 8365: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 17.867178, Loss/localization_loss = 3.28338, Loss/regularization_loss = 0.12599312, Loss/total_loss = 21.276552, global_step = 8365, learning_rate = 0.004, loss = 21.276552\n","I0816 01:27:50.430340 139955924342656 estimator.py:2049] Saving dict for global step 8365: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 17.867178, Loss/localization_loss = 3.28338, Loss/regularization_loss = 0.12599312, Loss/total_loss = 21.276552, global_step = 8365, learning_rate = 0.004, loss = 21.276552\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8365: my_data/output/model.ckpt-8365\n","I0816 01:27:50.438045 139955924342656 estimator.py:2109] Saving 'checkpoint_path' summary for global step 8365: my_data/output/model.ckpt-8365\n","INFO:tensorflow:global_step/sec: 0.579746\n","I0816 01:30:19.594882 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.579746\n","INFO:tensorflow:loss = 0.6243882, step = 8457 (172.489 sec)\n","I0816 01:30:19.596462 139955924342656 basic_session_run_hooks.py:260] loss = 0.6243882, step = 8457 (172.489 sec)\n","INFO:tensorflow:global_step/sec: 0.615208\n","I0816 01:33:02.141687 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.615208\n","INFO:tensorflow:loss = 1.5583649, step = 8557 (162.547 sec)\n","I0816 01:33:02.143238 139955924342656 basic_session_run_hooks.py:260] loss = 1.5583649, step = 8557 (162.547 sec)\n","INFO:tensorflow:global_step/sec: 0.626824\n","I0816 01:35:41.676147 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.626824\n","INFO:tensorflow:loss = 1.3296038, step = 8657 (159.535 sec)\n","I0816 01:35:41.677879 139955924342656 basic_session_run_hooks.py:260] loss = 1.3296038, step = 8657 (159.535 sec)\n","INFO:tensorflow:Saving checkpoints for 8731 into my_data/output/model.ckpt.\n","I0816 01:37:41.415999 139955924342656 basic_session_run_hooks.py:606] Saving checkpoints for 8731 into my_data/output/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 01:37:42.387929 139955924342656 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 01:37:42.389572 139955924342656 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0816 01:37:42.389720 139955924342656 dataset_builder.py:81] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0816 01:37:43.106259 139955924342656 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:37:44.396302 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:37:44.427589 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:37:44.455522 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:37:44.483682 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:37:44.511539 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:37:44.539421 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0816 01:37:45.683954 139955924342656 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-08-16T01:37:45Z\n","I0816 01:37:45.698217 139955924342656 evaluation.py:255] Starting evaluation at 2021-08-16T01:37:45Z\n","INFO:tensorflow:Graph was finalized.\n","I0816 01:37:45.937132 139955924342656 monitored_session.py:240] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from my_data/output/model.ckpt-8731\n","I0816 01:37:45.939566 139955924342656 saver.py:1284] Restoring parameters from my_data/output/model.ckpt-8731\n","INFO:tensorflow:Running local_init_op.\n","I0816 01:37:46.448919 139955924342656 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0816 01:37:46.540295 139955924342656 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 8 images.\n","I0816 01:37:49.273321 139954629330688 coco_evaluation.py:293] Performing evaluation on 8 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0816 01:37:49.273806 139954629330688 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0816 01:37:49.274120 139954629330688 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.00s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","INFO:tensorflow:Finished evaluation at 2021-08-16-01:37:50\n","I0816 01:37:50.366839 139955924342656 evaluation.py:275] Finished evaluation at 2021-08-16-01:37:50\n","INFO:tensorflow:Saving dict for global step 8731: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 18.423492, Loss/localization_loss = 3.3336878, Loss/regularization_loss = 0.12661289, Loss/total_loss = 21.883793, global_step = 8731, learning_rate = 0.004, loss = 21.883793\n","I0816 01:37:50.367104 139955924342656 estimator.py:2049] Saving dict for global step 8731: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 18.423492, Loss/localization_loss = 3.3336878, Loss/regularization_loss = 0.12661289, Loss/total_loss = 21.883793, global_step = 8731, learning_rate = 0.004, loss = 21.883793\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8731: my_data/output/model.ckpt-8731\n","I0816 01:37:50.374865 139955924342656 estimator.py:2109] Saving 'checkpoint_path' summary for global step 8731: my_data/output/model.ckpt-8731\n","INFO:tensorflow:global_step/sec: 0.588425\n","I0816 01:38:31.621452 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.588425\n","INFO:tensorflow:loss = 2.2318335, step = 8757 (169.945 sec)\n","I0816 01:38:31.622456 139955924342656 basic_session_run_hooks.py:260] loss = 2.2318335, step = 8757 (169.945 sec)\n","INFO:tensorflow:global_step/sec: 0.624387\n","I0816 01:41:11.778394 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.624387\n","INFO:tensorflow:loss = 2.008725, step = 8857 (160.157 sec)\n","I0816 01:41:11.779795 139955924342656 basic_session_run_hooks.py:260] loss = 2.008725, step = 8857 (160.157 sec)\n","INFO:tensorflow:global_step/sec: 0.617538\n","I0816 01:43:53.711706 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.617538\n","INFO:tensorflow:loss = 0.984782, step = 8957 (161.934 sec)\n","I0816 01:43:53.713442 139955924342656 basic_session_run_hooks.py:260] loss = 0.984782, step = 8957 (161.934 sec)\n","INFO:tensorflow:global_step/sec: 0.632601\n","I0816 01:46:31.789140 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.632601\n","INFO:tensorflow:loss = 3.4559004, step = 9057 (158.077 sec)\n","I0816 01:46:31.790629 139955924342656 basic_session_run_hooks.py:260] loss = 3.4559004, step = 9057 (158.077 sec)\n","INFO:tensorflow:Saving checkpoints for 9100 into my_data/output/model.ckpt.\n","I0816 01:47:42.033120 139955924342656 basic_session_run_hooks.py:606] Saving checkpoints for 9100 into my_data/output/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 01:47:43.014569 139955924342656 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 01:47:43.016066 139955924342656 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0816 01:47:43.016202 139955924342656 dataset_builder.py:81] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0816 01:47:43.730627 139955924342656 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:47:45.342751 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:47:45.370108 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:47:45.396782 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:47:45.424689 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:47:45.451485 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:47:45.478597 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0816 01:47:46.644500 139955924342656 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-08-16T01:47:46Z\n","I0816 01:47:46.658856 139955924342656 evaluation.py:255] Starting evaluation at 2021-08-16T01:47:46Z\n","INFO:tensorflow:Graph was finalized.\n","I0816 01:47:46.906464 139955924342656 monitored_session.py:240] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from my_data/output/model.ckpt-9100\n","I0816 01:47:46.908626 139955924342656 saver.py:1284] Restoring parameters from my_data/output/model.ckpt-9100\n","INFO:tensorflow:Running local_init_op.\n","I0816 01:47:47.488155 139955924342656 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0816 01:47:47.585455 139955924342656 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 8 images.\n","I0816 01:47:50.367349 139954637723392 coco_evaluation.py:293] Performing evaluation on 8 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0816 01:47:50.367924 139954637723392 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0816 01:47:50.368212 139954637723392 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.00s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","INFO:tensorflow:Finished evaluation at 2021-08-16-01:47:51\n","I0816 01:47:51.462592 139955924342656 evaluation.py:275] Finished evaluation at 2021-08-16-01:47:51\n","INFO:tensorflow:Saving dict for global step 9100: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 19.917887, Loss/localization_loss = 3.587018, Loss/regularization_loss = 0.1272561, Loss/total_loss = 23.63216, global_step = 9100, learning_rate = 0.004, loss = 23.63216\n","I0816 01:47:51.462842 139955924342656 estimator.py:2049] Saving dict for global step 9100: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 19.917887, Loss/localization_loss = 3.587018, Loss/regularization_loss = 0.1272561, Loss/total_loss = 23.63216, global_step = 9100, learning_rate = 0.004, loss = 23.63216\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9100: my_data/output/model.ckpt-9100\n","I0816 01:47:51.470253 139955924342656 estimator.py:2109] Saving 'checkpoint_path' summary for global step 9100: my_data/output/model.ckpt-9100\n","INFO:tensorflow:global_step/sec: 0.590626\n","I0816 01:49:21.100955 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.590626\n","INFO:tensorflow:loss = 1.0893236, step = 9157 (169.312 sec)\n","I0816 01:49:21.102572 139955924342656 basic_session_run_hooks.py:260] loss = 1.0893236, step = 9157 (169.312 sec)\n","INFO:tensorflow:global_step/sec: 0.628797\n","I0816 01:52:00.134782 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.628797\n","INFO:tensorflow:loss = 2.4293556, step = 9257 (159.034 sec)\n","I0816 01:52:00.136301 139955924342656 basic_session_run_hooks.py:260] loss = 2.4293556, step = 9257 (159.034 sec)\n","INFO:tensorflow:global_step/sec: 0.631609\n","I0816 01:54:38.460516 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.631609\n","INFO:tensorflow:loss = 3.8153012, step = 9357 (158.326 sec)\n","I0816 01:54:38.462223 139955924342656 basic_session_run_hooks.py:260] loss = 3.8153012, step = 9357 (158.326 sec)\n","INFO:tensorflow:global_step/sec: 0.623869\n","I0816 01:57:18.750610 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.623869\n","INFO:tensorflow:loss = 4.5923066, step = 9457 (160.290 sec)\n","I0816 01:57:18.752131 139955924342656 basic_session_run_hooks.py:260] loss = 4.5923066, step = 9457 (160.290 sec)\n","INFO:tensorflow:Saving checkpoints for 9472 into my_data/output/model.ckpt.\n","I0816 01:57:42.580683 139955924342656 basic_session_run_hooks.py:606] Saving checkpoints for 9472 into my_data/output/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 01:57:43.668318 139955924342656 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 01:57:43.670011 139955924342656 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0816 01:57:43.670163 139955924342656 dataset_builder.py:81] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0816 01:57:44.427807 139955924342656 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:57:45.813814 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:57:45.845132 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:57:45.874495 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:57:45.902247 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:57:45.930172 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 01:57:45.960379 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0816 01:57:47.432131 139955924342656 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-08-16T01:57:47Z\n","I0816 01:57:47.447177 139955924342656 evaluation.py:255] Starting evaluation at 2021-08-16T01:57:47Z\n","INFO:tensorflow:Graph was finalized.\n","I0816 01:57:47.698725 139955924342656 monitored_session.py:240] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from my_data/output/model.ckpt-9472\n","I0816 01:57:47.701363 139955924342656 saver.py:1284] Restoring parameters from my_data/output/model.ckpt-9472\n","INFO:tensorflow:Running local_init_op.\n","I0816 01:57:48.275035 139955924342656 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0816 01:57:48.375450 139955924342656 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 8 images.\n","I0816 01:57:51.464150 139954637723392 coco_evaluation.py:293] Performing evaluation on 8 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0816 01:57:51.464670 139954637723392 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0816 01:57:51.464979 139954637723392 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.01s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","INFO:tensorflow:Finished evaluation at 2021-08-16-01:57:52\n","I0816 01:57:52.635089 139955924342656 evaluation.py:275] Finished evaluation at 2021-08-16-01:57:52\n","INFO:tensorflow:Saving dict for global step 9472: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 20.423977, Loss/localization_loss = 3.4601078, Loss/regularization_loss = 0.12789835, Loss/total_loss = 24.011982, global_step = 9472, learning_rate = 0.004, loss = 24.011982\n","I0816 01:57:52.635396 139955924342656 estimator.py:2049] Saving dict for global step 9472: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 20.423977, Loss/localization_loss = 3.4601078, Loss/regularization_loss = 0.12789835, Loss/total_loss = 24.011982, global_step = 9472, learning_rate = 0.004, loss = 24.011982\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9472: my_data/output/model.ckpt-9472\n","I0816 01:57:52.643532 139955924342656 estimator.py:2109] Saving 'checkpoint_path' summary for global step 9472: my_data/output/model.ckpt-9472\n","INFO:tensorflow:global_step/sec: 0.586802\n","I0816 02:00:09.165796 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.586802\n","INFO:tensorflow:loss = 1.3785717, step = 9557 (170.415 sec)\n","I0816 02:00:09.167302 139955924342656 basic_session_run_hooks.py:260] loss = 1.3785717, step = 9557 (170.415 sec)\n","INFO:tensorflow:global_step/sec: 0.622772\n","I0816 02:02:49.738081 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.622772\n","INFO:tensorflow:loss = 1.1416512, step = 9657 (160.572 sec)\n","I0816 02:02:49.739695 139955924342656 basic_session_run_hooks.py:260] loss = 1.1416512, step = 9657 (160.572 sec)\n","INFO:tensorflow:global_step/sec: 0.624584\n","I0816 02:05:29.844768 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.624584\n","INFO:tensorflow:loss = 1.5804863, step = 9757 (160.107 sec)\n","I0816 02:05:29.846433 139955924342656 basic_session_run_hooks.py:260] loss = 1.5804863, step = 9757 (160.107 sec)\n","INFO:tensorflow:Saving checkpoints for 9840 into my_data/output/model.ckpt.\n","I0816 02:07:44.084543 139955924342656 basic_session_run_hooks.py:606] Saving checkpoints for 9840 into my_data/output/model.ckpt.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 02:07:45.151399 139955924342656 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 02:07:45.152993 139955924342656 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0816 02:07:45.153146 139955924342656 dataset_builder.py:81] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0816 02:07:45.904380 139955924342656 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:07:47.313170 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:07:47.343229 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:07:47.371658 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:07:47.400983 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:07:47.434127 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:07:47.462921 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0816 02:07:48.714238 139955924342656 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-08-16T02:07:48Z\n","I0816 02:07:48.731040 139955924342656 evaluation.py:255] Starting evaluation at 2021-08-16T02:07:48Z\n","INFO:tensorflow:Graph was finalized.\n","I0816 02:07:49.002966 139955924342656 monitored_session.py:240] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from my_data/output/model.ckpt-9840\n","I0816 02:07:49.005182 139955924342656 saver.py:1284] Restoring parameters from my_data/output/model.ckpt-9840\n","INFO:tensorflow:Running local_init_op.\n","I0816 02:07:49.551114 139955924342656 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0816 02:07:49.650886 139955924342656 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 8 images.\n","I0816 02:07:52.366516 139954637723392 coco_evaluation.py:293] Performing evaluation on 8 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0816 02:07:52.367042 139954637723392 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0816 02:07:52.367308 139954637723392 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.01s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","INFO:tensorflow:Finished evaluation at 2021-08-16-02:07:53\n","I0816 02:07:53.573436 139955924342656 evaluation.py:275] Finished evaluation at 2021-08-16-02:07:53\n","INFO:tensorflow:Saving dict for global step 9840: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 16.831556, Loss/localization_loss = 3.299921, Loss/regularization_loss = 0.12856196, Loss/total_loss = 20.260036, global_step = 9840, learning_rate = 0.004, loss = 20.260036\n","I0816 02:07:53.573710 139955924342656 estimator.py:2049] Saving dict for global step 9840: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 16.831556, Loss/localization_loss = 3.299921, Loss/regularization_loss = 0.12856196, Loss/total_loss = 20.260036, global_step = 9840, learning_rate = 0.004, loss = 20.260036\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9840: my_data/output/model.ckpt-9840\n","I0816 02:07:53.583583 139955924342656 estimator.py:2109] Saving 'checkpoint_path' summary for global step 9840: my_data/output/model.ckpt-9840\n","INFO:tensorflow:global_step/sec: 0.585852\n","I0816 02:08:20.536177 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.585852\n","INFO:tensorflow:loss = 0.9376764, step = 9857 (170.691 sec)\n","I0816 02:08:20.537148 139955924342656 basic_session_run_hooks.py:260] loss = 0.9376764, step = 9857 (170.691 sec)\n","INFO:tensorflow:global_step/sec: 0.619725\n","I0816 02:11:01.898029 139955924342656 basic_session_run_hooks.py:692] global_step/sec: 0.619725\n","INFO:tensorflow:loss = 0.79686904, step = 9957 (161.362 sec)\n","I0816 02:11:01.899498 139955924342656 basic_session_run_hooks.py:260] loss = 0.79686904, step = 9957 (161.362 sec)\n","INFO:tensorflow:Saving checkpoints for 10000 into my_data/output/model.ckpt.\n","I0816 02:12:10.975425 139955924342656 basic_session_run_hooks.py:606] Saving checkpoints for 10000 into my_data/output/model.ckpt.\n","INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n","I0816 02:12:11.974820 139955924342656 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 02:12:12.000066 139955924342656 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","I0816 02:12:12.001962 139955924342656 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/My Drive/tf_od_demo/my_data/train_data.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0816 02:12:12.002123 139955924342656 dataset_builder.py:81] Number of filenames to read: 1\n","INFO:tensorflow:Calling model_fn.\n","I0816 02:12:12.740116 139955924342656 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:12:14.369614 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:12:14.397002 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:12:14.425195 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:12:14.451828 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:12:14.479152 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:12:14.505538 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0816 02:12:15.655939 139955924342656 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2021-08-16T02:12:15Z\n","I0816 02:12:15.670299 139955924342656 evaluation.py:255] Starting evaluation at 2021-08-16T02:12:15Z\n","INFO:tensorflow:Graph was finalized.\n","I0816 02:12:15.902930 139955924342656 monitored_session.py:240] Graph was finalized.\n","INFO:tensorflow:Restoring parameters from my_data/output/model.ckpt-10000\n","I0816 02:12:15.905485 139955924342656 saver.py:1284] Restoring parameters from my_data/output/model.ckpt-10000\n","INFO:tensorflow:Running local_init_op.\n","I0816 02:12:16.427508 139955924342656 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0816 02:12:16.525744 139955924342656 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 8 images.\n","I0816 02:12:19.063261 139954637723392 coco_evaluation.py:293] Performing evaluation on 8 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0816 02:12:19.063728 139954637723392 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0816 02:12:19.064030 139954637723392 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.00s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","INFO:tensorflow:Finished evaluation at 2021-08-16-02:12:20\n","I0816 02:12:20.312306 139955924342656 evaluation.py:275] Finished evaluation at 2021-08-16-02:12:20\n","INFO:tensorflow:Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 16.389174, Loss/localization_loss = 3.095951, Loss/regularization_loss = 0.12887394, Loss/total_loss = 19.613997, global_step = 10000, learning_rate = 0.004, loss = 19.613997\n","I0816 02:12:20.312597 139955924342656 estimator.py:2049] Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.0, DetectionBoxes_Precision/mAP (large) = 0.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0, DetectionBoxes_Precision/mAP@.75IOU = 0.0, DetectionBoxes_Recall/AR@1 = 0.0, DetectionBoxes_Recall/AR@10 = 0.0, DetectionBoxes_Recall/AR@100 = 0.0, DetectionBoxes_Recall/AR@100 (large) = 0.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 16.389174, Loss/localization_loss = 3.095951, Loss/regularization_loss = 0.12887394, Loss/total_loss = 19.613997, global_step = 10000, learning_rate = 0.004, loss = 19.613997\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: my_data/output/model.ckpt-10000\n","I0816 02:12:20.320757 139955924342656 estimator.py:2109] Saving 'checkpoint_path' summary for global step 10000: my_data/output/model.ckpt-10000\n","INFO:tensorflow:Performing the final export in the end of training.\n","I0816 02:12:20.321707 139955924342656 exporter.py:410] Performing the final export in the end of training.\n","INFO:tensorflow:Calling model_fn.\n","I0816 02:12:20.596662 139955924342656 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:12:21.886668 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:12:21.914418 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:12:21.940627 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:12:21.967396 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:12:21.993231 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:12:22.019188 139955924342656 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0816 02:12:22.529145 139955924342656 estimator.py:1150] Done calling model_fn.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0816 02:12:22.529458 139955924342656 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","I0816 02:12:22.529999 139955924342656 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","I0816 02:12:22.530114 139955924342656 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","I0816 02:12:22.530193 139955924342656 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","I0816 02:12:22.530271 139955924342656 export_utils.py:170] Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","I0816 02:12:22.530346 139955924342656 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n","INFO:tensorflow:Restoring parameters from my_data/output/model.ckpt-10000\n","I0816 02:12:22.534094 139955924342656 saver.py:1284] Restoring parameters from my_data/output/model.ckpt-10000\n","INFO:tensorflow:Assets added to graph.\n","I0816 02:12:22.788223 139955924342656 builder_impl.py:665] Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","I0816 02:12:22.788444 139955924342656 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: my_data/output/export/Servo/temp-b'1629079940'/saved_model.pb\n","I0816 02:12:23.295743 139955924342656 builder_impl.py:425] SavedModel written to: my_data/output/export/Servo/temp-b'1629079940'/saved_model.pb\n","INFO:tensorflow:Loss for final step: 2.059304.\n","I0816 02:12:23.443577 139955924342656 estimator.py:371] Loss for final step: 2.059304.\n","CPU times: user 28.8 s, sys: 3.64 s, total: 32.5 s\n","Wall time: 1h 15min 38s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zEREUliJ5VQm"},"source":["### Заморозка модели\n","Для того, чтобы использовать обученную модель в режиме инференса, её нужно \"заморозить\". Другими словами - подготовить к инференсу. Для этого надо запустить скрипт `export_inference_graph.py` и передать соответствующие парамтеры.\n","\n","* Путь к файлу `pipeline.config`\n","* Путь к весам обученной модели (`trained_checkpoint_prefix`)\n","* Путь к директории для сохранения замороженной модели (`output_directory`)"]},{"cell_type":"code","metadata":{"id":"cFdrE7VYkxNi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629080024391,"user_tz":-180,"elapsed":11764,"user":{"displayName":"Александр Чернавин","photoUrl":"","userId":"12809599521665994243"}},"outputId":"cd7e9ac6-9ebd-4d92-84fb-d4ae4b79b036"},"source":["!export PYTHONPATH=$PYTHONPATH:models/research:models/research/slim ; python models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path=my_data/pipeline.config \\\n","    --trained_checkpoint_prefix=my_data/output/model.ckpt-10000 \\\n","    --output_directory=my_data/output/frozen/"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0816 02:13:39.402275 140219477587840 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:13:40.895388 140219477587840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:13:40.932954 140219477587840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:13:40.969221 140219477587840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:13:41.003919 140219477587840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:13:41.040167 140219477587840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0816 02:13:41.076528 140219477587840 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/drive/My Drive/tf_od_demo/models/research/object_detection/core/post_processing.py:601: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0816 02:13:41.332208 140219477587840 deprecation.py:323] From /content/drive/My Drive/tf_od_demo/models/research/object_detection/core/post_processing.py:601: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/My Drive/tf_od_demo/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0816 02:13:41.666318 140219477587840 deprecation.py:323] From /content/drive/My Drive/tf_od_demo/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /content/drive/My Drive/tf_od_demo/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0816 02:13:41.669471 140219477587840 deprecation.py:323] From /content/drive/My Drive/tf_od_demo/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0816 02:13:41.669937 140219477587840 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","108 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/5.49m params)\n","  BoxPredictor_0 (--/9.23k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.16k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n","    BoxPredictor_0/ClassPredictor (--/3.08k params)\n","      BoxPredictor_0/ClassPredictor/biases (6, 6/6 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x512x6, 3.07k/3.07k params)\n","  BoxPredictor_1 (--/36.90k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/24.60k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1024x24, 24.58k/24.58k params)\n","    BoxPredictor_1/ClassPredictor (--/12.30k params)\n","      BoxPredictor_1/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1024x12, 12.29k/12.29k params)\n","  BoxPredictor_2 (--/18.47k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/6.16k params)\n","      BoxPredictor_2/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n","  BoxPredictor_3 (--/9.25k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/3.08k params)\n","      BoxPredictor_3/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n","  BoxPredictor_4 (--/9.25k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/3.08k params)\n","      BoxPredictor_4/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n","  BoxPredictor_5 (--/4.64k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/1.55k params)\n","      BoxPredictor_5/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x12, 1.54k/1.54k params)\n","  FeatureExtractor (--/5.41m params)\n","    FeatureExtractor/MobilenetV1 (--/5.41m params)\n","      FeatureExtractor/MobilenetV1/Conv2d_0 (--/864 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_0/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV1/Conv2d_10_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_10_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_11_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_11_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_12_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_12_pointwise (--/524.29k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights (1x1x512x1024, 524.29k/524.29k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_depthwise (--/9.22k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights (3x3x1024x1, 9.22k/9.22k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise (--/1.05m params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights (1x1x1024x1024, 1.05m/1.05m params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256 (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights (1x1x1024x256, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_1_depthwise (--/288 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","      FeatureExtractor/MobilenetV1/Conv2d_1_pointwise (--/2.05k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights (1x1x32x64, 2.05k/2.05k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_2_depthwise (--/576 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n","      FeatureExtractor/MobilenetV1/Conv2d_2_pointwise (--/8.19k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights (1x1x64x128, 8.19k/8.19k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_3_depthwise (--/1.15k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_3_pointwise (--/16.38k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights (1x1x128x128, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_4_depthwise (--/1.15k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_4_pointwise (--/32.77k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights (1x1x128x256, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_5_depthwise (--/2.30k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_5_pointwise (--/65.54k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights (1x1x256x256, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_6_depthwise (--/2.30k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_6_pointwise (--/131.07k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights (1x1x256x512, 131.07k/131.07k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_7_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_7_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_8_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_8_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_9_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_9_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","\n","======================End of Report==========================\n","108 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/13.71k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","\n","======================End of Report==========================\n","2021-08-16 02:13:43.144590: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2021-08-16 02:13:43.148288: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000175000 Hz\n","2021-08-16 02:13:43.148473: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5651fd6e99c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-08-16 02:13:43.148503: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","INFO:tensorflow:Restoring parameters from my_data/output/model.ckpt-10000\n","I0816 02:13:43.151090 140219477587840 saver.py:1284] Restoring parameters from my_data/output/model.ckpt-10000\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0816 02:13:43.872301 140219477587840 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from my_data/output/model.ckpt-10000\n","I0816 02:13:44.272200 140219477587840 saver.py:1284] Restoring parameters from my_data/output/model.ckpt-10000\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0816 02:13:44.637264 140219477587840 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0816 02:13:44.637543 140219477587840 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 199 variables.\n","I0816 02:13:45.012866 140219477587840 graph_util_impl.py:334] Froze 199 variables.\n","INFO:tensorflow:Converted 199 variables to const ops.\n","I0816 02:13:45.082874 140219477587840 graph_util_impl.py:394] Converted 199 variables to const ops.\n","WARNING:tensorflow:From /content/drive/My Drive/tf_od_demo/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0816 02:13:45.522567 140219477587840 deprecation.py:323] From /content/drive/My Drive/tf_od_demo/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:No assets to save.\n","I0816 02:13:45.523270 140219477587840 builder_impl.py:640] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I0816 02:13:45.523423 140219477587840 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: my_data/output/frozen/saved_model/saved_model.pb\n","I0816 02:13:45.774919 140219477587840 builder_impl.py:425] SavedModel written to: my_data/output/frozen/saved_model/saved_model.pb\n","INFO:tensorflow:Writing pipeline config file to my_data/output/frozen/pipeline.config\n","I0816 02:13:45.793141 140219477587840 config_util.py:254] Writing pipeline config file to my_data/output/frozen/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"90_1TKZ6md4D"},"source":[""],"execution_count":null,"outputs":[]}]}